{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = './chromedriver.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA COLLECTION\n",
    "titles = []\n",
    "locations = []\n",
    "companies = []\n",
    "salaries = []\n",
    "all_li_text = []\n",
    "jobtitles = []\n",
    "i = 0\n",
    "\n",
    "urls = ['https://www.indeed.co.in/jobs?q=machine+learning&l=India&start={i}',\n",
    "        'https://www.indeed.co.in/jobs?q=artificial+intelligence&l=India&start={i}',\n",
    "        'https://www.indeed.co.in/jobs?q=data+science&l=India&start={i}',\n",
    "        'https://www.indeed.co.in/jobs?q=data+analytics&l=India&start={i}',\n",
    "        'https://www.indeed.co.in/jobs?q=web+development&l=India&start={i}',\n",
    "        'https://www.indeed.co.in/jobs?q=django+developer&l=India&start={i}',\n",
    "        'https://www.indeed.co.in/jobs?q=react+js&l=India&start={i}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in urls:  \n",
    "    \n",
    "    titles = []\n",
    "    locations = []\n",
    "    companies = []\n",
    "    salaries = []\n",
    "    all_li_text = []\n",
    "    jobtitles = []\n",
    "\n",
    "    for i in range(0, 500, 10):\n",
    "        sleep(2.5)\n",
    "        browser.get(j.format(i=i))\n",
    "        cards = browser.find_elements_by_class_name('result')\n",
    "        for info in cards:\n",
    "            details = BeautifulSoup(info.get_attribute('innerHTML'), 'html.parser')\n",
    "\n",
    "            try:\n",
    "                title = details.find('a', class_ = 'jobtitle').text.replace('\\n', '')\n",
    "                titles.append(title)\n",
    "            except:\n",
    "                titles.append(None)\n",
    "\n",
    "            try:\n",
    "                location = details.find(class_ = 'location').text.replace('\\n', '')\n",
    "                locations.append(location)\n",
    "            except:\n",
    "                locations.append(None)\n",
    "\n",
    "            try:\n",
    "                company = details.find(class_ = 'company').text.replace('\\n', '')\n",
    "                companies.append(company)\n",
    "            except:\n",
    "                companies.append(None)\n",
    "\n",
    "            try:\n",
    "                salary = details.find(class_ = 'salary').text.replace('\\n', '')\n",
    "                salaries.append(salary)\n",
    "            except:\n",
    "                salaries.append(None)\n",
    "\n",
    "            info.click()\n",
    "            sleep(1)\n",
    "\n",
    "            try:\n",
    "                des = browser.find_element_by_id(\"vjs-desc\")\n",
    "                decHTML = BeautifulSoup(des.get_attribute('innerHTML'), 'html.parser')\n",
    "                all_li = decHTML.find_all('li')\n",
    "\n",
    "                for i in all_li:\n",
    "                    all_li_text.append(i.text.replace('\\n',''))\n",
    "                jobtitles.append(all_li_text)\n",
    "\n",
    "            except Exception as e:\n",
    "                \n",
    "                jobtitles.append(None)\n",
    "\n",
    "    dic = {\n",
    "    'Titles':titles,\n",
    "    'Locations':locations,\n",
    "    'Companies':companies,\n",
    "    'Salaries':salaries,\n",
    "    'JobDescription':jobtitles\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(dic)\n",
    "    df.to_csv(re.findall(r'[a-z]*.\\+[a-z]*', j)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling popups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in urls:  \n",
    "    \n",
    "    titles = []\n",
    "    locations = []\n",
    "    companies = []\n",
    "    salaries = []\n",
    "    all_li_text = []\n",
    "    jobtitles = []\n",
    "\n",
    "    for i in range(0, 500, 10):\n",
    "        browser.get(j.format(i=i))\n",
    "        sleep(2.5)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                cards = browser.find_elements_by_class_name('result')\n",
    "                break\n",
    "            except:              \n",
    "                popUp = browser.find_element_by_id('popover-x')\n",
    "                popUp.click()\n",
    "                   \n",
    "        for info in cards:\n",
    "            details = BeautifulSoup(info.get_attribute('innerHTML'), 'html.parser')\n",
    "\n",
    "            try:\n",
    "                title = details.find('a', class_ = 'jobtitle').text.replace('\\n', '')\n",
    "                titles.append(title)\n",
    "            except:\n",
    "                titles.append(None)\n",
    "\n",
    "            try:\n",
    "                location = details.find(class_ = 'location').text.replace('\\n', '')\n",
    "                locations.append(location)\n",
    "            except:\n",
    "                locations.append(None)\n",
    "\n",
    "            try:\n",
    "                company = details.find(class_ = 'company').text.replace('\\n', '')\n",
    "                companies.append(company)\n",
    "            except:\n",
    "                companies.append(None)\n",
    "\n",
    "            try:\n",
    "                salary = details.find(class_ = 'salary').text.replace('\\n', '')\n",
    "                salaries.append(salary)\n",
    "            except:\n",
    "                salaries.append(None)\n",
    "\n",
    "           while True:\n",
    "            try:\n",
    "                \n",
    "                info.click()\n",
    "                sleep(1)\n",
    "\n",
    "                try:\n",
    "                    des = browser.find_element_by_id(\"vjs-desc\")\n",
    "                    decHTML = BeautifulSoup(des.get_attribute('innerHTML'), 'html.parser')\n",
    "                    all_li = decHTML.find_all('li')\n",
    "\n",
    "                    for i in all_li:\n",
    "                    all_li_text.append(i.text.replace('\\n',''))\n",
    "                    jobtitles.append(all_li_text)\n",
    "\n",
    "                except Exception as e:\n",
    "                    jobtitles.append(None)\n",
    "                break\n",
    "                \n",
    "            except:\n",
    "                popUp = browser.find_element_by_id('popover-x')\n",
    "                popUp.click()\n",
    "\n",
    "\n",
    "    dic = {\n",
    "    'Titles':titles,\n",
    "    'Locations':locations,\n",
    "    'Companies':companies,\n",
    "    'Salaries':salaries,\n",
    "    'JobDescription':jobtitles\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(dic)\n",
    "    df.to_csv(re.findall(r'[a-z]*.\\+[a-z]*', j)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('ai.csv')                   # File names are different and will be depending on the context\n",
    "df2 = pd.read_csv('data_analyst.csv')\n",
    "df3 = pd.read_csv('datascience2.csv')\n",
    "df4 = pd.read_csv ('machinelearning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4], axis = 0)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df.groupby('Company').count()['Title'].sort_values(ascending = False)[:10][::-1]   # Finding the first 10 comapnies with max job offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp.plot(kind = 'barh', figsize = (15,5)) # Visualising the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################Cleaning the Data using NLP #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def Clean(desc):\n",
    "    words = word_tokenize(str(desc))\n",
    "    imp_words = []\n",
    "    for word in words:\n",
    "        lower = word.lower()\n",
    "        if lower not in stop_words:\n",
    "            imp_words.append(lower)\n",
    "    return imp_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = df['Description'].dropna().apply(Clean)\n",
    "res = tags.apply(Counter)\n",
    "f_res = res.sum().items()\n",
    "f_res = list(f_res)\n",
    "f_res = sorted(f_res, key = lambda kv:kv[1], reverse = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series({\n",
    "    k:v for k,v in f_res\n",
    "})\n",
    "\n",
    "skills = ['python', 'opencv', 'pandas', 'math', 'nltk']\n",
    "Filter = series.filter(items = skills)[::-1]         # skills list contain set of skills mentioned in the job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filter.plot(kind = 'barh', figsize = (10,5))           # Visualizing the filtered data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
